
1
00:00:00,021 --> 00:00:01,087
Let's start talking about logistic regression.

2
00:00:02,095 --> 00:00:04,009
In this video, I'd like to

3
00:00:04,025 --> 00:00:07,000
show you the hypothesis representation, that

4
00:00:07,020 --> 00:00:08,018
is, what is the function

5
00:00:08,081 --> 00:00:09,078
we're going to use to represent

6
00:00:10,030 --> 00:00:13,016
our hypothesis where we have a classification problem.

7
00:00:15,044 --> 00:00:16,080
Earlier, we said that we

8
00:00:16,092 --> 00:00:18,075
would like our classifier to

9
00:00:20,037 --> 00:00:21,071
output values that are between

10
00:00:21,092 --> 00:00:23,005
zero and one. So, we

11
00:00:23,026 --> 00:00:24,008
like to come up with a

12
00:00:24,055 --> 00:00:26,017
hypothesis that satisfies this

13
00:00:26,037 --> 00:00:29,012
property, that these predictions are maybe between zero and one.

14
00:00:30,035 --> 00:00:31,078
When we were using linear regression,

15
00:00:32,072 --> 00:00:33,077
this was the form of a

16
00:00:34,025 --> 00:00:35,021
hypothesis, where H of X

17
00:00:35,059 --> 00:00:38,014
is theta transpose X.  For

18
00:00:38,032 --> 00:00:39,057
logistic regression, I'm going

19
00:00:39,075 --> 00:00:40,085
to modify this a little

20
00:00:41,004 --> 00:00:42,006
bit, and make the hypothesis

21
00:00:43,035 --> 00:00:45,007
G of theta transpose X,

22
00:00:46,020 --> 00:00:47,002
where I'm going to define

23
00:00:47,060 --> 00:00:50,014
the function G as follows:

24
00:00:50,067 --> 00:00:51,067
G of Z if Z

25
00:00:51,090 --> 00:00:53,031
is a real number is equal

26
00:00:53,064 --> 00:00:55,003
to one over one plus

27
00:00:55,063 --> 00:00:58,007
E to the negative Z. This

28
00:00:58,049 --> 00:01:00,046
called the sigmoid function

29
00:01:01,071 --> 00:01:03,089
or the logistic function.

30
00:01:04,084 --> 00:01:06,031
And the term logistic function,

31
00:01:07,012 --> 00:01:09,057
that's what give rise to the name logistic progression.

32
00:01:11,009 --> 00:01:12,012
And, by the way, the terms

33
00:01:12,075 --> 00:01:14,009
sigmoid function and logistic

34
00:01:14,054 --> 00:01:16,012
function are basically synonyms

35
00:01:16,093 --> 00:01:17,067
and mean the same thing.

36
00:01:18,029 --> 00:01:19,048
So the two terms are

37
00:01:19,073 --> 00:01:21,054
basically interchangeable and either

38
00:01:21,087 --> 00:01:22,095
term can be used to

39
00:01:23,009 --> 00:01:24,021
refer to this function

40
00:01:24,060 --> 00:01:26,012
G.
And if we

41
00:01:26,028 --> 00:01:27,034
take these two equations, and

42
00:01:27,071 --> 00:01:29,071
put them together, then here's

43
00:01:30,007 --> 00:01:32,017
just an alternative way of

44
00:01:32,034 --> 00:01:33,092
writing out the form of my hypothesis.

45
00:01:34,084 --> 00:01:35,081
I'm saying that H of x

46
00:01:36,054 --> 00:01:38,040
is one over one plus

47
00:01:38,090 --> 00:01:41,015
E to the negative theta transpose

48
00:01:41,075 --> 00:01:42,082
X, and all I've done is

49
00:01:43,009 --> 00:01:44,076
I've taken the variable

50
00:01:45,032 --> 00:01:46,070
Z, Z here's a

51
00:01:46,076 --> 00:01:48,004
real number and plugged in

52
00:01:48,017 --> 00:01:49,093
theta transpose X, so

53
00:01:50,020 --> 00:01:51,095
I end up with, you know, theta transpose

54
00:01:52,056 --> 00:01:53,098
X, in place of Z there.

55
00:01:54,093 --> 00:01:57,078
Lastly, let me show you where the sigmoid function looks like.

56
00:01:57,090 --> 00:01:59,021
We're going to plot it on this figure here.

57
00:02:00,028 --> 00:02:01,090
The sigmoid function, G of

58
00:02:02,001 --> 00:02:04,035
Z, also called the logistic function, looks like this.

59
00:02:04,062 --> 00:02:06,093
It starts off near zero and

60
00:02:07,004 --> 00:02:08,068
then rises until it processes

61
00:02:09,036 --> 00:02:12,075
0.5 at the origin and then it flattens out again like so.

62
00:02:13,050 --> 00:02:15,018
So that's what the sigmoid function looks like.

63
00:02:16,003 --> 00:02:17,075
And you notice that the

64
00:02:17,087 --> 00:02:19,050
sigmoid function, well, it

65
00:02:19,074 --> 00:02:21,071
asymptotes at one, and

66
00:02:21,084 --> 00:02:23,040
asymptotes at zero as

67
00:02:24,025 --> 00:02:26,005
Z against the horizontal axis

68
00:02:26,037 --> 00:02:27,049
is Z. As Z goes to

69
00:02:27,059 --> 00:02:29,012
minus infinity, G of

70
00:02:29,028 --> 00:02:31,015
Z approaches zero and as

71
00:02:31,038 --> 00:02:33,053
G of Z approaches infinity, G

72
00:02:33,075 --> 00:02:35,047
of Z approaches 1, and

73
00:02:35,087 --> 00:02:37,015
so because G of

74
00:02:37,024 --> 00:02:38,087
Z offers values that are

75
00:02:39,037 --> 00:02:40,025
between 0 and 1 we

76
00:02:41,072 --> 00:02:44,050
also have that H of

77
00:02:44,061 --> 00:02:46,047
X must be between 0 and 1.

78
00:02:47,012 --> 00:02:49,046
Finally, given this hypothesis

79
00:02:50,003 --> 00:02:52,000
representation, what we

80
00:02:52,009 --> 00:02:53,011
need to do, as before,

81
00:02:53,071 --> 00:02:57,097
is fit the parameters theta to our data.

82
00:02:59,016 --> 00:03:00,028
So given a training set, we

83
00:03:00,041 --> 00:03:01,059
need to pick a value for

84
00:03:01,072 --> 00:03:03,062
the parameters theta and this

85
00:03:03,074 --> 00:03:05,071
hypothesis will then let us make predictions.

86
00:03:06,097 --> 00:03:08,015
We'll talk about a learning algorithm

87
00:03:08,053 --> 00:03:10,068
later for fitting the parameters theta.

88
00:03:11,080 --> 00:03:13,043
But first let's talk a

89
00:03:13,046 --> 00:03:15,084
bit about the interpretation of this model.

90
00:03:18,061 --> 00:03:19,052
Here's how I'm going to

91
00:03:19,062 --> 00:03:21,043
interpret the output of

92
00:03:21,061 --> 00:03:23,053
my hypothesis H of

93
00:03:23,062 --> 00:03:25,047
X.  When my hypothesis

94
00:03:26,040 --> 00:03:28,009
outputs some number, I am

95
00:03:28,024 --> 00:03:29,087
going to treat that number as

96
00:03:30,006 --> 00:03:33,019
the estimated probability that Y

97
00:03:33,037 --> 00:03:34,093
is equal to one on a

98
00:03:35,009 --> 00:03:38,049
new input example X. Here is what I mean.

99
00:03:38,059 --> 00:03:39,013
Here is an example.

100
00:03:40,028 --> 00:03:42,084
Let's say we're using the tumor classification example.

101
00:03:43,091 --> 00:03:45,005
So we may have a feature

102
00:03:45,018 --> 00:03:47,012
vector X, which is this x01

103
00:03:47,093 --> 00:03:49,065
as always and then our

104
00:03:49,080 --> 00:03:51,038
one feature is the size of the tumor.

105
00:03:52,083 --> 00:03:53,083
Suppose I have a patient come

106
00:03:54,000 --> 00:03:54,088
in and, you know they have some

107
00:03:55,041 --> 00:03:57,003
tumor size and I

108
00:03:57,015 --> 00:03:58,038
feed their feature vector X

109
00:03:58,072 --> 00:04:00,063
into my hypothesis and suppose

110
00:04:00,096 --> 00:04:02,072
my hypothesis outputs the number 0.7.

111
00:04:03,071 --> 00:04:05,002
I'm going to interpret

112
00:04:05,072 --> 00:04:06,075
my hypothesis as follows.

113
00:04:07,028 --> 00:04:08,056
I'm going to say that this

114
00:04:08,077 --> 00:04:10,002
hypothesis is telling me

115
00:04:10,022 --> 00:04:11,099
that for a patient with

116
00:04:12,012 --> 00:04:13,068
features X, the probability

117
00:04:14,052 --> 00:04:16,068
that Y equals one is 0  .7.

118
00:04:16,075 --> 00:04:18,055
In other words, I'm going

119
00:04:18,072 --> 00:04:20,082
to tell my patient that the

120
00:04:21,006 --> 00:04:23,086
tumor, sadly, has

121
00:04:24,031 --> 00:04:26,016
a 70% chance or a 0.7 chance of being malignant.

122
00:04:27,086 --> 00:04:29,018
To write this out slightly more

123
00:04:29,037 --> 00:04:30,031
formally or to write this

124
00:04:30,048 --> 00:04:31,063
out in math, I'm going to

125
00:04:31,074 --> 00:04:33,085
interpret my hypothesis output

126
00:04:34,081 --> 00:04:36,095
as P of y

127
00:04:37,014 --> 00:04:38,079
equals 1, given X

128
00:04:39,089 --> 00:04:40,068
parametrized by theta.

129
00:04:41,082 --> 00:04:43,001
So, for those of you that are

130
00:04:43,027 --> 00:04:44,088
familiar with probability, this equation

131
00:04:45,031 --> 00:04:46,049
might make sense, if you're a little less familiar

132
00:04:46,073 --> 00:04:48,051
with probability, you know, here's

133
00:04:48,063 --> 00:04:51,037
how I read this expression, this

134
00:04:51,057 --> 00:04:53,000
is the probability that y is

135
00:04:53,013 --> 00:04:54,064
equals to one, given x

136
00:04:54,097 --> 00:04:55,093
instead of given that my patient

137
00:04:56,048 --> 00:04:57,072
has, you know, features X.

138
00:04:58,004 --> 00:04:59,043
Given my patient has a particular

139
00:04:59,082 --> 00:05:01,036
tumor size represented by my

140
00:05:01,051 --> 00:05:02,091
features X, and this

141
00:05:03,013 --> 00:05:05,070
probability is parametrized by theta.

142
00:05:07,012 --> 00:05:08,072
So I'm basically going to count

143
00:05:09,010 --> 00:05:10,063
on my hypothesis to give

144
00:05:10,094 --> 00:05:12,004
me estimates of the probability

145
00:05:13,029 --> 00:05:14,077
that Y is equal to 1.

146
00:05:15,031 --> 00:05:16,039
Now since this is a

147
00:05:16,048 --> 00:05:18,025
classification task, we know

148
00:05:18,063 --> 00:05:20,099
that Y must be either zero or one, right?

149
00:05:21,048 --> 00:05:22,081
Those are the only two values

150
00:05:23,038 --> 00:05:24,081
that Y could possibly take on,

151
00:05:25,029 --> 00:05:26,047
either in the training set or

152
00:05:26,062 --> 00:05:27,076
for new patients that may walk

153
00:05:28,006 --> 00:05:30,060
into my office or into the doctor's office in the future.

154
00:05:32,031 --> 00:05:33,016
So given H of X,

155
00:05:33,055 --> 00:05:35,002
we can therefore compute the probability

156
00:05:36,012 --> 00:05:38,004
that Y is equal to zero as well.

157
00:05:39,006 --> 00:05:41,004
Concretely, because Y must

158
00:05:41,025 --> 00:05:42,044
be either zero or one,

159
00:05:43,006 --> 00:05:44,044
we know that the probability

160
00:05:45,012 --> 00:05:46,016
of Y equals zero, plus the

161
00:05:46,025 --> 00:05:47,022
probability of Y equals

162
00:05:47,055 --> 00:05:48,077
one, must add up to one.

163
00:05:50,025 --> 00:05:51,032
This first equation looks a

164
00:05:51,045 --> 00:05:52,068
little bit more complicated but it's

165
00:05:52,077 --> 00:05:54,025
basically saying that probability of

166
00:05:54,061 --> 00:05:56,018
Y equals zero for a

167
00:05:56,031 --> 00:05:58,014
particular patient with features x, and

168
00:05:58,036 --> 00:06:00,070
you know, given our parameter's data, plus the

169
00:06:01,000 --> 00:06:02,008
probability of Y equals one for

170
00:06:02,029 --> 00:06:03,083
that same patient which features x and you

171
00:06:04,043 --> 00:06:03,083


172
00:06:04,043 --> 00:06:03,083


173
00:06:04,043 --> 00:06:06,014
parameters theta must add

174
00:06:06,036 --> 00:06:07,082
up to one, if this equation

175
00:06:08,025 --> 00:06:09,091
looks a little bit complicated feel free

176
00:06:10,019 --> 00:06:13,005
to mentally imagine it without that X and theta.

177
00:06:14,027 --> 00:06:15,019
And this is just saying that

178
00:06:15,048 --> 00:06:16,063
the probability of Y equals zero plus

179
00:06:16,092 --> 00:06:18,077
the probability of Y equals one must be equal to one.

180
00:06:19,027 --> 00:06:20,014
And we know this to be

181
00:06:20,024 --> 00:06:22,092
true because Y has to be either zero or one.

182
00:06:23,008 --> 00:06:24,000
And so the chance of Y

183
00:06:24,020 --> 00:06:25,057
being zero plus the chance

184
00:06:25,093 --> 00:06:28,043
that Y is one, you know, those two must add up to one.

185
00:06:29,054 --> 00:06:30,068
And so if you just

186
00:06:31,043 --> 00:06:33,057
take this term and move

187
00:06:33,075 --> 00:06:35,024
it to the right-hand side, then

188
00:06:35,039 --> 00:06:36,081
you end up with this equation

189
00:06:37,030 --> 00:06:38,037
that says probability Y equals zero

190
00:06:38,095 --> 00:06:40,020
is one minus probability y equals

191
00:06:40,052 --> 00:06:42,081
and thus if our

192
00:06:43,056 --> 00:06:45,004
hypothesis if H of X

193
00:06:45,095 --> 00:06:47,056
gives us that term you can

194
00:06:47,079 --> 00:06:49,081
therefore quite simply compute the

195
00:06:49,088 --> 00:06:51,017
probability, or compute the

196
00:06:51,050 --> 00:06:52,099
estimated probability that Y

197
00:06:53,025 --> 00:06:54,055
is equal to zero as well.

198
00:06:55,031 --> 00:06:56,031
So you now know what

199
00:06:56,063 --> 00:06:59,041
the hypothesis representation is for

200
00:06:59,079 --> 00:07:01,032
logistic regression and we're seeing

201
00:07:01,057 --> 00:07:03,031
what the mathematical formula is

202
00:07:03,050 --> 00:07:05,063
defining the hypothesis for logistic regression.

203
00:07:06,062 --> 00:07:07,068
In the next video, I'd like

204
00:07:07,087 --> 00:07:08,087
to try to give you

205
00:07:09,004 --> 00:07:10,062
better intuition about what the

206
00:07:11,005 --> 00:07:12,018
hypothesis function looks like.

207
00:07:12,049 --> 00:07:13,052
And I want to tell

208
00:07:13,062 --> 00:07:14,070
you something called the decision

209
00:07:15,020 --> 00:07:16,047
boundary and we'll look

210
00:07:16,066 --> 00:07:18,060
at some visualizations together to

211
00:07:18,083 --> 00:07:19,070
try to get a better sense

212
00:07:20,013 --> 00:07:22,017
of what this hypothesis function of

213
00:07:22,036 --> 00:07:23,075
logistic regression really looks like.
