
1
00:00:00,020 --> 00:00:01,077
By now you've seen the anomaly

2
00:00:02,025 --> 00:00:03,054
detection algorithm and we've

3
00:00:03,074 --> 00:00:05,024
also talked about how to

4
00:00:05,057 --> 00:00:06,087
evaluate an anomaly detection

5
00:00:07,033 --> 00:00:08,088
algorithm. It turns out,

6
00:00:09,052 --> 00:00:10,080
that when you're applying anomaly

7
00:00:11,016 --> 00:00:12,040
detection, one of the

8
00:00:12,046 --> 00:00:13,028
things that has a huge

9
00:00:13,072 --> 00:00:14,085
effect on how well it

10
00:00:14,093 --> 00:00:16,044
does, is what features you

11
00:00:16,051 --> 00:00:17,071
use, and what features you choose,

12
00:00:18,053 --> 00:00:19,091
to give the anomaly detection algorithm.

13
00:00:20,082 --> 00:00:22,017
So in this video, what I'd

14
00:00:22,028 --> 00:00:23,039
like to do is say a few

15
00:00:23,048 --> 00:00:24,089
words, give some suggestions and

16
00:00:25,000 --> 00:00:26,025
guidelines for how to

17
00:00:26,037 --> 00:00:27,092
go about designing or selecting

18
00:00:28,046 --> 00:00:30,094
features give to an anomaly detection algorithm.

19
00:00:33,092 --> 00:00:35,031
In our anomaly detection algorithm,

20
00:00:36,011 --> 00:00:37,027
one of the things we did was

21
00:00:37,050 --> 00:00:40,032
model the features using this sort of Gaussian distribution.

22
00:00:41,017 --> 00:00:42,081
With xi to mu

23
00:00:43,011 --> 00:00:46,004
i, sigma squared i, lets say.

24
00:00:46,054 --> 00:00:47,089
And so one thing that

25
00:00:47,095 --> 00:00:49,061
I often do would be to plot the

26
00:00:50,067 --> 00:00:52,025
data or the histogram of

27
00:00:52,032 --> 00:00:53,049
the data, to make sure that

28
00:00:53,093 --> 00:00:55,021
the data looks vaguely

29
00:00:55,053 --> 00:00:57,032
Gaussian before feeding it

30
00:00:57,046 --> 00:00:58,082
to my anomaly detection algorithm.

31
00:00:59,081 --> 00:01:01,003
And, it'll usually work okay,

32
00:01:01,060 --> 00:01:02,082
even if your data isn't Gaussian,

33
00:01:03,039 --> 00:01:05,070
but this is sort of a nice sanitary check to run.

34
00:01:05,096 --> 00:01:06,085
And by the way, in case your data

35
00:01:07,040 --> 00:01:09,054
looks non-Gaussian, the algorithms will often work just find.

36
00:01:10,040 --> 00:01:12,006
But, concretely if I

37
00:01:12,043 --> 00:01:13,051
plot the data like this,

38
00:01:13,084 --> 00:01:15,028
and if it looks like a histogram like

39
00:01:15,037 --> 00:01:16,048
this, and the way

40
00:01:16,062 --> 00:01:17,079
to plot a histogram is to

41
00:01:17,095 --> 00:01:19,090
use the HIST, or the

42
00:01:20,012 --> 00:01:21,081
HIST command in Octave,

43
00:01:21,090 --> 00:01:22,079
but it looks like this, this looks

44
00:01:23,001 --> 00:01:24,076
vaguely Gaussian, so if

45
00:01:24,093 --> 00:01:26,020
my features look like this,

46
00:01:26,048 --> 00:01:29,096
I would be pretty happy feeding into my algorithm.

47
00:01:30,018 --> 00:01:31,082
But if i were to plot a histogram of my

48
00:01:31,095 --> 00:01:33,006
data, and it were

49
00:01:33,020 --> 00:01:34,079
to look like this well, this

50
00:01:35,006 --> 00:01:36,009
doesn't look at all like a

51
00:01:36,021 --> 00:01:38,043
bell shaped curve, this is a very asymmetric distribution,

52
00:01:39,040 --> 00:01:40,065
it has a peak way off to one side.

53
00:01:41,075 --> 00:01:42,065
If this is what my data

54
00:01:42,079 --> 00:01:43,095
looks like, what I'll often

55
00:01:44,018 --> 00:01:45,037
do is play with different

56
00:01:45,073 --> 00:01:46,092
transformations of the data in order

57
00:01:47,001 --> 00:01:48,084
to make it look more Gaussian.

58
00:01:49,048 --> 00:01:51,093
And again the algorithm will usually work okay, even if you don't.

59
00:01:52,059 --> 00:01:53,065
But if you use these transformations

60
00:01:54,062 --> 00:01:56,059
to make your data more gaussian, it might work a bit better.

61
00:01:58,003 --> 00:01:59,078
So given the data set

62
00:02:00,014 --> 00:02:01,034
that looks like this, what I

63
00:02:01,043 --> 00:02:02,081
might do is take a

64
00:02:03,001 --> 00:02:04,051
log transformation of the

65
00:02:04,065 --> 00:02:05,093
data and if i

66
00:02:06,006 --> 00:02:07,081
do that and re-plot the

67
00:02:08,015 --> 00:02:09,011
histogram, what I end up

68
00:02:09,033 --> 00:02:10,050
with in this particular example,

69
00:02:11,012 --> 00:02:12,040
is a histogram that looks like this.

70
00:02:12,053 --> 00:02:14,046
And this looks much more Gaussian, right?

71
00:02:14,065 --> 00:02:15,071
This looks much more like the classic

72
00:02:16,068 --> 00:02:18,002
bell shaped curve, that we

73
00:02:18,071 --> 00:02:21,000
can fit with some mean and variance paramater sigma.

74
00:02:22,018 --> 00:02:22,093
So what I mean by taking

75
00:02:23,022 --> 00:02:24,061
a log transform, is really that

76
00:02:24,086 --> 00:02:26,013
if I have some feature x1 and

77
00:02:26,086 --> 00:02:28,025
then the histogram of x1 looks

78
00:02:28,071 --> 00:02:30,050
like this then I might

79
00:02:31,006 --> 00:02:32,021
take my feature x1

80
00:02:32,040 --> 00:02:33,088
and replace it with log

81
00:02:34,080 --> 00:02:36,072
of x1 and this is

82
00:02:36,086 --> 00:02:37,087
my new x1 that I'll plot

83
00:02:38,016 --> 00:02:40,000
to the histogram over on the right, and this looks much

84
00:02:40,043 --> 00:02:42,034
more Guassian.

85
00:02:44,000 --> 00:02:44,072
Rather than just a log transform some other things you can

86
00:02:44,091 --> 00:02:46,002
do, might be, let's say

87
00:02:46,011 --> 00:02:47,071
I have a different feature x2,

88
00:02:48,068 --> 00:02:49,084
maybe I'll replace that will

89
00:02:50,012 --> 00:02:52,056
log x plus 1,

90
00:02:52,062 --> 00:02:54,071
or more generally with log

91
00:02:56,036 --> 00:02:57,068
x with x2 and

92
00:02:58,043 --> 00:03:00,034
some constant c and this

93
00:03:00,052 --> 00:03:01,053
constant could be something

94
00:03:01,088 --> 00:03:04,038
that I play with, to try to make it look as Gaussian as possible.

95
00:03:05,061 --> 00:03:06,081
Or for a different feature x3, maybe

96
00:03:07,019 --> 00:03:08,061
I'll replace it with x3,

97
00:03:09,072 --> 00:03:11,025
I might take the square root.

98
00:03:11,061 --> 00:03:14,018
The square root is just x3 to the power of one half, right?

99
00:03:15,025 --> 00:03:16,065
And this one half

100
00:03:17,012 --> 00:03:19,021
is another example of a parameter I can play with.

101
00:03:19,063 --> 00:03:21,059
So, I might have x4 and

102
00:03:22,044 --> 00:03:23,081
maybe I might instead replace

103
00:03:24,040 --> 00:03:25,037
that with x4 to the power

104
00:03:25,072 --> 00:03:26,078
of something else, maybe to the

105
00:03:26,088 --> 00:03:28,046
power of 1/3.

106
00:03:28,093 --> 00:03:30,083
And these, all of

107
00:03:30,090 --> 00:03:32,031
these, this one, this

108
00:03:32,053 --> 00:03:33,066
exponent parameter, or the

109
00:03:33,081 --> 00:03:35,011
C parameter, all of these

110
00:03:35,037 --> 00:03:36,087
are examples of parameters that

111
00:03:36,096 --> 00:03:38,011
you can play with in order

112
00:03:38,046 --> 00:03:40,041
to make your data look a little bit more Gaussian.

113
00:03:45,018 --> 00:03:46,021
So, let me show you a live demo

114
00:03:46,074 --> 00:03:48,071
of how I actually go about

115
00:03:49,015 --> 00:03:50,068
playing with my data to make it look more Gaussian.

116
00:03:51,065 --> 00:03:52,037
So, I have already loaded

117
00:03:52,075 --> 00:03:54,072
in to octave here a set

118
00:03:54,086 --> 00:03:56,016
of features x I have a thousand examples

119
00:03:57,015 --> 00:03:57,087
loaded over there.

120
00:03:58,058 --> 00:04:00,009
So let's pull up the histogram of my data.

121
00:04:01,056 --> 00:04:02,056
Use the hist x command.

122
00:04:03,018 --> 00:04:04,009
So there's my histogram.

123
00:04:05,065 --> 00:04:06,058
By default, I think this

124
00:04:06,068 --> 00:04:08,025
uses 10 bins of histograms,

125
00:04:08,061 --> 00:04:10,040
but I want to see a more fine grid histogram.

126
00:04:11,033 --> 00:04:12,094
So we do hist to the x, 50,

127
00:04:13,005 --> 00:04:14,096
so, this plots it in 50 different bins.

128
00:04:15,031 --> 00:04:15,065
Okay, that looks better.

129
00:04:16,018 --> 00:04:18,056
Now, this doesn't look very Gaussian, does it?

130
00:04:18,093 --> 00:04:20,072
So, lets start playing around with the data.

131
00:04:20,089 --> 00:04:22,031
Lets try a hist of

132
00:04:22,061 --> 00:04:24,081
x to the 0.5.

133
00:04:25,008 --> 00:04:26,058
So we take the

134
00:04:26,087 --> 00:04:28,081
square root of the data, and plot that histogram.

135
00:04:30,067 --> 00:04:31,068
And, okay, it looks

136
00:04:31,080 --> 00:04:32,087
a little bit more Gaussian, but not

137
00:04:32,095 --> 00:04:34,055
quite there, so let's play at the 0.5 parameter.

138
00:04:34,079 --> 00:04:35,032
Let's see.

139
00:04:36,051 --> 00:04:38,011
Set this to 0.2.

140
00:04:38,027 --> 00:04:39,077
Looks a little bit more Gaussian.

141
00:04:40,093 --> 00:04:43,014
Let's reduce a little bit more 0.1.

142
00:04:44,044 --> 00:04:45,022
Yeah, that looks pretty good.

143
00:04:45,050 --> 00:04:48,043
I could actually just use 0.1.

144
00:04:48,087 --> 00:04:50,018
Well, let's reduce it to 0.05.

145
00:04:50,051 --> 00:04:50,091
And, you know?

146
00:04:51,074 --> 00:04:52,075
Okay, this looks pretty Gaussian,

147
00:04:53,023 --> 00:04:54,008
so I can define a new

148
00:04:54,018 --> 00:04:55,050
feature which is x mu equals

149
00:04:56,011 --> 00:04:58,093
x to the 0.05,

150
00:04:59,062 --> 00:05:01,037
and now my new

151
00:05:01,061 --> 00:05:03,005
feature x Mu looks more

152
00:05:03,025 --> 00:05:04,049
Gaussian than my previous one

153
00:05:04,050 --> 00:05:05,056
and then I might instead use

154
00:05:05,085 --> 00:05:07,006
this new feature to feed

155
00:05:07,037 --> 00:05:09,038
into my anomaly detection algorithm.

156
00:05:10,014 --> 00:05:12,010
And of course, there is more than one way to do this.

157
00:05:12,041 --> 00:05:14,052
You could also have hist of log of

158
00:05:14,070 --> 00:05:17,031
x, that's another example of a transformation you can use.

159
00:05:18,026 --> 00:05:20,041
And, you know, that also look pretty Gaussian.

160
00:05:20,087 --> 00:05:22,004
So, I can also define x

161
00:05:22,023 --> 00:05:23,075
mu equals log of x.

162
00:05:24,022 --> 00:05:25,012
and that would be another

163
00:05:25,030 --> 00:05:26,088
pretty good choice of a feature to use.

164
00:05:28,004 --> 00:05:29,039
So to summarize, if you

165
00:05:29,051 --> 00:05:30,057
plot a histogram with the data,

166
00:05:31,000 --> 00:05:31,068
and find that it looks pretty

167
00:05:31,093 --> 00:05:33,045
non-Gaussian, it's worth playing

168
00:05:33,074 --> 00:05:35,011
around a little bit with

169
00:05:35,027 --> 00:05:37,012
different transformations like these, to

170
00:05:37,029 --> 00:05:38,018
see if you can make

171
00:05:38,030 --> 00:05:39,041
your data look a little bit more

172
00:05:39,056 --> 00:05:40,051
Gaussian, before you feed it to

173
00:05:40,076 --> 00:05:41,097
your learning algorithm, although even if

174
00:05:42,005 --> 00:05:43,055
you don't, it might work okay.

175
00:05:43,085 --> 00:05:45,006
But I usually do take this step.

176
00:05:45,085 --> 00:05:46,087
Now, the second thing I want

177
00:05:46,097 --> 00:05:48,027
to talk about is, how do

178
00:05:48,039 --> 00:05:51,054
you come up with features for an anomaly detection algorithm.

179
00:05:52,064 --> 00:05:53,077
And the way I often do

180
00:05:53,099 --> 00:05:56,049
so, is via an error analysis procedure.

181
00:05:57,062 --> 00:05:58,058
So what I mean by that,

182
00:05:58,097 --> 00:05:59,095
is that this is really similar

183
00:06:00,031 --> 00:06:02,031
to the error analysis procedure that

184
00:06:02,044 --> 00:06:04,060
we have for supervised learning, where

185
00:06:04,086 --> 00:06:06,081
we would train a

186
00:06:06,086 --> 00:06:08,022
complete algorithm, and run the

187
00:06:08,035 --> 00:06:09,098
algorithm on a cross validation set,

188
00:06:10,083 --> 00:06:11,087
and look at the examples it gets

189
00:06:12,023 --> 00:06:13,050
wrong, and see if

190
00:06:13,057 --> 00:06:14,080
we can come up with extra features

191
00:06:15,037 --> 00:06:16,043
to help the algorithm do

192
00:06:16,057 --> 00:06:17,087
better on the examples

193
00:06:18,027 --> 00:06:19,085
that it got wrong in the cross-validation set.

194
00:06:21,006 --> 00:06:23,037
So lets try

195
00:06:24,004 --> 00:06:25,095
to reason through an example of this process.

196
00:06:26,094 --> 00:06:28,068
In anomaly detection, we are

197
00:06:28,087 --> 00:06:29,068
hoping that p of x will

198
00:06:29,083 --> 00:06:30,091
be large for the normal examples

199
00:06:31,075 --> 00:06:33,018
and it will be small for the anomalous examples.

200
00:06:34,039 --> 00:06:35,037
And so a pretty common problem

201
00:06:35,094 --> 00:06:37,077
would be if p of x is comparable,

202
00:06:38,048 --> 00:06:41,054
maybe both are large for both the normal and the anomalous examples.

203
00:06:42,093 --> 00:06:44,037
Lets look at a specific example of that.

204
00:06:45,014 --> 00:06:46,075
Let's say that this is my unlabeled data.

205
00:06:47,012 --> 00:06:47,097
So, here I have just one

206
00:06:48,020 --> 00:06:51,012
feature, x1 and so I'm gonna fit a Gaussian to this.

207
00:06:52,016 --> 00:06:55,099
And maybe my Gaussian that I fit to my data looks like that.

208
00:06:57,030 --> 00:06:59,012
And now let's say I have an anomalous example,

209
00:06:59,067 --> 00:07:00,048
and let's say that my anomalous example

210
00:07:01,007 --> 00:07:02,085
takes on an x value of 2.5.

211
00:07:03,001 --> 00:07:06,042
So I plot my anomalous example there.

212
00:07:07,019 --> 00:07:08,012
And you know, it's kind of buried

213
00:07:08,064 --> 00:07:09,073
in the middle of a bunch

214
00:07:09,087 --> 00:07:11,068
of normal examples, and so,

215
00:07:13,044 --> 00:07:14,085
just this anomalous example

216
00:07:15,045 --> 00:07:16,077
that I've drawn in green, it gets a

217
00:07:16,081 --> 00:07:18,055
pretty high probability, where it's the

218
00:07:18,073 --> 00:07:20,000
height of the blue curve,

219
00:07:20,095 --> 00:07:22,027
and the algorithm fails to

220
00:07:22,038 --> 00:07:23,083
flag this as an anomalous example.

221
00:07:25,031 --> 00:07:26,060
Now, if this were maybe aircraft

222
00:07:27,000 --> 00:07:29,054
engine manufacturing or something, what

223
00:07:29,068 --> 00:07:30,049
I would do is, I would actually

224
00:07:30,086 --> 00:07:32,037
look at my training examples and

225
00:07:32,083 --> 00:07:34,050
look at what went wrong with

226
00:07:34,073 --> 00:07:36,092
that particular aircraft engine, and

227
00:07:37,002 --> 00:07:38,036
see, if looking at that

228
00:07:38,072 --> 00:07:40,072
example can inspire me to

229
00:07:40,086 --> 00:07:41,080
come up with a new feature

230
00:07:42,029 --> 00:07:43,088
x2, that helps to distinguish

231
00:07:44,064 --> 00:07:46,052
between this bad example, compared

232
00:07:46,089 --> 00:07:47,085
to the rest of my

233
00:07:48,052 --> 00:07:49,085
red examples, compared to all

234
00:07:50,098 --> 00:07:51,060
of my normal aircraft engines.

235
00:07:52,079 --> 00:07:53,083
And if I managed to do

236
00:07:54,000 --> 00:07:54,091
so, the hope would be then,

237
00:07:55,014 --> 00:07:56,054
that, if I can create a

238
00:07:56,061 --> 00:07:59,036
new feature, X2, so that

239
00:07:59,061 --> 00:08:01,049
when I re-plot my data, if

240
00:08:01,057 --> 00:08:02,052
I take all my normal examples

241
00:08:02,076 --> 00:08:04,042
of my training set, hopefully

242
00:08:04,075 --> 00:08:05,056
I find that all my training

243
00:08:05,070 --> 00:08:07,037
examples are these red crosses here.

244
00:08:08,020 --> 00:08:09,057
And hopefully, if I find

245
00:08:09,086 --> 00:08:11,038
that for my anomalous example, the

246
00:08:11,048 --> 00:08:13,049
feature x2 takes on the the unusual value.

247
00:08:14,047 --> 00:08:15,081
So for my green example

248
00:08:16,029 --> 00:08:18,067
here, this anomaly, right, my

249
00:08:18,093 --> 00:08:20,080
X1 value, is still 2.5.

250
00:08:21,025 --> 00:08:22,089
Then maybe my X2 value, hopefully

251
00:08:23,029 --> 00:08:24,052
it takes on a very large

252
00:08:24,083 --> 00:08:26,070
value like 3.5 over there,

253
00:08:27,093 --> 00:08:28,044
or a very small value.

254
00:08:29,044 --> 00:08:30,052
But now, if I model

255
00:08:30,097 --> 00:08:32,048
my data, I'll find that

256
00:08:33,004 --> 00:08:34,065
my anomaly detection algorithm gives

257
00:08:35,024 --> 00:08:36,083
high probability to data

258
00:08:37,019 --> 00:08:39,015
in the central regions, slightly lower

259
00:08:39,020 --> 00:08:42,047
probability to that, sightly lower probability to that.

260
00:08:42,065 --> 00:08:43,096
An example that's all the

261
00:08:44,007 --> 00:08:45,045
way out there, my algorithm will

262
00:08:45,062 --> 00:08:46,072
now give very low probability

263
00:08:48,036 --> 00:08:48,036
to.

264
00:08:48,050 --> 00:08:49,016
And so, the process of this

265
00:08:49,023 --> 00:08:50,032
is, really look at the

266
00:08:51,042 --> 00:08:52,057
mistakes that it is making.

267
00:08:52,083 --> 00:08:54,037
Look at the anomaly that the algorithm

268
00:08:54,058 --> 00:08:56,001
is failing to flag, and see

269
00:08:56,032 --> 00:08:59,010
if that inspires you to create some new feature.

270
00:08:59,059 --> 00:09:01,017
So find something unusual about

271
00:09:01,047 --> 00:09:02,059
that aircraft engine and use

272
00:09:02,079 --> 00:09:03,063
that to create a new feature,

273
00:09:04,052 --> 00:09:05,077
so that with this new

274
00:09:05,089 --> 00:09:07,013
feature it becomes easier to

275
00:09:07,039 --> 00:09:09,025
distinguish the anomalies from your good examples.

276
00:09:09,087 --> 00:09:11,016
And so that's the

277
00:09:11,027 --> 00:09:12,060
process of error analysis

278
00:09:14,001 --> 00:09:15,036
and using that to create

279
00:09:15,075 --> 00:09:17,010
new features for anomaly detection.

280
00:09:17,076 --> 00:09:18,098
Finally, let me share with

281
00:09:19,009 --> 00:09:20,044
you my thinking on how I

282
00:09:20,062 --> 00:09:23,019
usually go about choosing features for anomaly detection.

283
00:09:24,035 --> 00:09:27,070
So, usually, the way I think about choosing features is

284
00:09:27,096 --> 00:09:29,015
I want to choose features that will

285
00:09:29,026 --> 00:09:30,061
take on either very, very

286
00:09:30,086 --> 00:09:32,000
large values, or very, very

287
00:09:32,011 --> 00:09:33,088
small values, for examples

288
00:09:34,075 --> 00:09:36,041
that I think might turn out to be anomalies.

289
00:09:37,085 --> 00:09:38,071
So let's use our example

290
00:09:39,005 --> 00:09:41,082
again of monitoring the computers in a data center.

291
00:09:42,025 --> 00:09:43,055
And so you have lots of

292
00:09:43,062 --> 00:09:44,092
machines, maybe thousands, or tens

293
00:09:45,016 --> 00:09:47,083
of thousands of machines in a data center.

294
00:09:48,030 --> 00:09:49,040
And we want to know if one

295
00:09:49,058 --> 00:09:50,063
of the machines, one of our

296
00:09:50,071 --> 00:09:53,032
computers is acting up, so doing something strange.

297
00:09:54,017 --> 00:09:56,004
So here are examples of features you may choose,

298
00:09:57,001 --> 00:09:59,062
maybe memory used, number of disc accesses, CPU load, network traffic.

299
00:10:01,003 --> 00:10:01,096
But now, lets say that I

300
00:10:02,022 --> 00:10:03,003
suspect one of the failure

301
00:10:03,047 --> 00:10:04,058
cases, let's say that

302
00:10:05,023 --> 00:10:06,097
in my data set I think

303
00:10:07,014 --> 00:10:08,046
that CPU load the network traffic

304
00:10:08,099 --> 00:10:10,082
tend to grow linearly with each other.

305
00:10:11,011 --> 00:10:12,012
Maybe I'm running a bunch of

306
00:10:12,022 --> 00:10:13,037
web servers, and so, here

307
00:10:13,075 --> 00:10:15,004
if one of my servers is

308
00:10:15,030 --> 00:10:16,052
serving a lot of users,

309
00:10:16,085 --> 00:10:19,004
I have a very high CPU load, and have a very high network traffic.

310
00:10:20,023 --> 00:10:21,036
But let's say, I think,

311
00:10:21,084 --> 00:10:23,027
let's say I have a suspicion, that

312
00:10:23,038 --> 00:10:24,088
one of the failure cases is

313
00:10:25,017 --> 00:10:26,024
if one of my computers

314
00:10:26,052 --> 00:10:29,059
has a job that gets stuck in some infinite loop.

315
00:10:29,066 --> 00:10:30,075
So if I think one of

316
00:10:30,079 --> 00:10:32,024
the failure cases, is one of

317
00:10:32,041 --> 00:10:33,047
my machines, one of my

318
00:10:34,037 --> 00:10:36,001
web servers--server code--

319
00:10:36,067 --> 00:10:37,099
gets stuck in some infinite loop,

320
00:10:38,023 --> 00:10:39,054
and so the CPU load grows,

321
00:10:40,037 --> 00:10:41,049
but the network traffic doesn't because

322
00:10:41,055 --> 00:10:42,078
it's just spinning it's

323
00:10:42,094 --> 00:10:44,057
wheels and doing a lot of CPU work, you know,

324
00:10:44,087 --> 00:10:46,000
stuck in some infinite loop.

325
00:10:46,092 --> 00:10:47,085
In that case, to detect

326
00:10:48,024 --> 00:10:49,061
that type of anomaly, I might

327
00:10:49,077 --> 00:10:52,044
create a new feature, X5,

328
00:10:53,016 --> 00:10:55,012
which might be CPU load

329
00:10:56,060 --> 00:11:00,012
divided by network traffic.

330
00:11:01,023 --> 00:11:02,080
And so here X5 will take

331
00:11:03,017 --> 00:11:04,086
on a unusually large value

332
00:11:05,070 --> 00:11:06,040
if one of the machines has a

333
00:11:06,078 --> 00:11:08,019
very large CPU load but

334
00:11:08,047 --> 00:11:09,098
not that much network traffic and

335
00:11:10,025 --> 00:11:11,002
so this will be a

336
00:11:11,015 --> 00:11:12,038
feature that will help your

337
00:11:12,049 --> 00:11:14,017
anomaly detection capture, a certain type of anomaly.

338
00:11:15,000 --> 00:11:16,070
And you can

339
00:11:16,084 --> 00:11:19,005
also get creative and come up with other features as well.

340
00:11:19,023 --> 00:11:20,009
Like maybe I have a feature

341
00:11:20,057 --> 00:11:22,004
x6 thats CPU load

342
00:11:22,087 --> 00:11:25,053
squared divided by network traffic.

343
00:11:27,002 --> 00:11:28,027
And this would be another variant

344
00:11:28,095 --> 00:11:29,090
of a feature like x5 to try

345
00:11:30,001 --> 00:11:32,012
to capture anomalies where one

346
00:11:32,027 --> 00:11:33,064
of your machines has a very

347
00:11:33,079 --> 00:11:35,002
high CPU load, that maybe

348
00:11:35,028 --> 00:11:37,010
doesn't have a commensurately large network traffic.

349
00:11:38,053 --> 00:11:40,008
And by creating features like

350
00:11:40,028 --> 00:11:41,055
these, you can start to capture

351
00:11:42,076 --> 00:11:44,054
anomalies that correspond to

352
00:11:45,069 --> 00:11:48,026
unusual combinations of values of the features.

353
00:11:50,099 --> 00:11:52,009
So in this video we

354
00:11:52,025 --> 00:11:53,054
talked about how to and

355
00:11:53,069 --> 00:11:54,066
take a feature, and maybe transform

356
00:11:55,012 --> 00:11:56,067
it a little bit, so that

357
00:11:56,083 --> 00:11:57,090
it becomes a bit more Gaussian,

358
00:11:58,025 --> 00:12:00,048
before feeding into an anomaly detection algorithm.

359
00:12:00,095 --> 00:12:02,011
And also the error analysis

360
00:12:02,074 --> 00:12:04,022
in this process of creating features

361
00:12:04,087 --> 00:12:06,071
to try to capture different types of anomalies.

362
00:12:07,054 --> 00:12:10,029
And with these sorts of guidelines hopefully that will help you

363
00:12:10,085 --> 00:12:12,017
to choose good features, to give to

364
00:12:12,046 --> 00:12:14,030
your anomaly detection algorithm, to

365
00:12:14,042 --> 00:12:15,091
help it capture all sorts of anomalies.
